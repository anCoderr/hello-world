{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a3f85c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68dc7de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Model for initializing a NN Model\n",
    "class Model(nn.Module): # Must write\n",
    "    \n",
    "    def __init__(self, in_features=4,h1=8,h2=9,out_features=3):\n",
    "        super().__init__() # Must write. It calls the constructor for nn.Module class\n",
    "        self.fc1 = nn.Linear(in_features, h1) # Creates i/p layer 1 with full connections b/w in_features and h1\n",
    "        self.fc2 = nn.Linear(h1, h2) # Hidden layer 2 creates full connections b/w h1 and h2\n",
    "        self.out = nn.Linear(h2, out_features) # O/p later 3 with full connections b/w h2 and out_features\n",
    "        \n",
    "    def forward(self, x): # Forward propogation method\n",
    "        x = F.relu(self.fc1(x)) # The o/p of 1st layer becomes i/p for 2nd layer\n",
    "        x = F.relu(self.fc2(x)) # The o/p of 2nd layer becomes i/p for 3rd layer\n",
    "        x = F.relu(self.out(x)) # The o/p of 3rd layer becomes the final output\n",
    "        return x # Return the final o/p as o/p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0418ad0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\AnCodeRR\\PYTORCH_NOTEBOOKS\\Data\\iris.csv\") # Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "720ff6b3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n0                  5.1               3.5                1.4               0.2   \n1                  4.9               3.0                1.4               0.2   \n2                  4.7               3.2                1.3               0.2   \n3                  4.6               3.1                1.5               0.2   \n4                  5.0               3.6                1.4               0.2   \n5                  5.4               3.9                1.7               0.4   \n6                  4.6               3.4                1.4               0.3   \n7                  5.0               3.4                1.5               0.2   \n8                  4.4               2.9                1.4               0.2   \n9                  4.9               3.1                1.5               0.1   \n10                 5.4               3.7                1.5               0.2   \n11                 4.8               3.4                1.6               0.2   \n12                 4.8               3.0                1.4               0.1   \n13                 4.3               3.0                1.1               0.1   \n14                 5.8               4.0                1.2               0.2   \n15                 5.7               4.4                1.5               0.4   \n16                 5.4               3.9                1.3               0.4   \n17                 5.1               3.5                1.4               0.3   \n18                 5.7               3.8                1.7               0.3   \n19                 5.1               3.8                1.5               0.3   \n20                 5.4               3.4                1.7               0.2   \n21                 5.1               3.7                1.5               0.4   \n22                 4.6               3.6                1.0               0.2   \n23                 5.1               3.3                1.7               0.5   \n24                 4.8               3.4                1.9               0.2   \n25                 5.0               3.0                1.6               0.2   \n26                 5.0               3.4                1.6               0.4   \n27                 5.2               3.5                1.5               0.2   \n28                 5.2               3.4                1.4               0.2   \n29                 4.7               3.2                1.6               0.2   \n..                 ...               ...                ...               ...   \n120                6.9               3.2                5.7               2.3   \n121                5.6               2.8                4.9               2.0   \n122                7.7               2.8                6.7               2.0   \n123                6.3               2.7                4.9               1.8   \n124                6.7               3.3                5.7               2.1   \n125                7.2               3.2                6.0               1.8   \n126                6.2               2.8                4.8               1.8   \n127                6.1               3.0                4.9               1.8   \n128                6.4               2.8                5.6               2.1   \n129                7.2               3.0                5.8               1.6   \n130                7.4               2.8                6.1               1.9   \n131                7.9               3.8                6.4               2.0   \n132                6.4               2.8                5.6               2.2   \n133                6.3               2.8                5.1               1.5   \n134                6.1               2.6                5.6               1.4   \n135                7.7               3.0                6.1               2.3   \n136                6.3               3.4                5.6               2.4   \n137                6.4               3.1                5.5               1.8   \n138                6.0               3.0                4.8               1.8   \n139                6.9               3.1                5.4               2.1   \n140                6.7               3.1                5.6               2.4   \n141                6.9               3.1                5.1               2.3   \n142                5.8               2.7                5.1               1.9   \n143                6.8               3.2                5.9               2.3   \n144                6.7               3.3                5.7               2.5   \n145                6.7               3.0                5.2               2.3   \n146                6.3               2.5                5.0               1.9   \n147                6.5               3.0                5.2               2.0   \n148                6.2               3.4                5.4               2.3   \n149                5.9               3.0                5.1               1.8   \n\n     target  \n0       0.0  \n1       0.0  \n2       0.0  \n3       0.0  \n4       0.0  \n5       0.0  \n6       0.0  \n7       0.0  \n8       0.0  \n9       0.0  \n10      0.0  \n11      0.0  \n12      0.0  \n13      0.0  \n14      0.0  \n15      0.0  \n16      0.0  \n17      0.0  \n18      0.0  \n19      0.0  \n20      0.0  \n21      0.0  \n22      0.0  \n23      0.0  \n24      0.0  \n25      0.0  \n26      0.0  \n27      0.0  \n28      0.0  \n29      0.0  \n..      ...  \n120     2.0  \n121     2.0  \n122     2.0  \n123     2.0  \n124     2.0  \n125     2.0  \n126     2.0  \n127     2.0  \n128     2.0  \n129     2.0  \n130     2.0  \n131     2.0  \n132     2.0  \n133     2.0  \n134     2.0  \n135     2.0  \n136     2.0  \n137     2.0  \n138     2.0  \n139     2.0  \n140     2.0  \n141     2.0  \n142     2.0  \n143     2.0  \n144     2.0  \n145     2.0  \n146     2.0  \n147     2.0  \n148     2.0  \n149     2.0  \n\n[150 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sepal length (cm)</th>\n      <th>sepal width (cm)</th>\n      <th>petal length (cm)</th>\n      <th>petal width (cm)</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5.1</td>\n      <td>3.5</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4.9</td>\n      <td>3.0</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4.7</td>\n      <td>3.2</td>\n      <td>1.3</td>\n      <td>0.2</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4.6</td>\n      <td>3.1</td>\n      <td>1.5</td>\n      <td>0.2</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5.0</td>\n      <td>3.6</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5.4</td>\n      <td>3.9</td>\n      <td>1.7</td>\n      <td>0.4</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>4.6</td>\n      <td>3.4</td>\n      <td>1.4</td>\n      <td>0.3</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>5.0</td>\n      <td>3.4</td>\n      <td>1.5</td>\n      <td>0.2</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>4.4</td>\n      <td>2.9</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>4.9</td>\n      <td>3.1</td>\n      <td>1.5</td>\n      <td>0.1</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>5.4</td>\n      <td>3.7</td>\n      <td>1.5</td>\n      <td>0.2</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>4.8</td>\n      <td>3.4</td>\n      <td>1.6</td>\n      <td>0.2</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>4.8</td>\n      <td>3.0</td>\n      <td>1.4</td>\n      <td>0.1</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>4.3</td>\n      <td>3.0</td>\n      <td>1.1</td>\n      <td>0.1</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>5.8</td>\n      <td>4.0</td>\n      <td>1.2</td>\n      <td>0.2</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>5.7</td>\n      <td>4.4</td>\n      <td>1.5</td>\n      <td>0.4</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>5.4</td>\n      <td>3.9</td>\n      <td>1.3</td>\n      <td>0.4</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>5.1</td>\n      <td>3.5</td>\n      <td>1.4</td>\n      <td>0.3</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>5.7</td>\n      <td>3.8</td>\n      <td>1.7</td>\n      <td>0.3</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>5.1</td>\n      <td>3.8</td>\n      <td>1.5</td>\n      <td>0.3</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>5.4</td>\n      <td>3.4</td>\n      <td>1.7</td>\n      <td>0.2</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>5.1</td>\n      <td>3.7</td>\n      <td>1.5</td>\n      <td>0.4</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>4.6</td>\n      <td>3.6</td>\n      <td>1.0</td>\n      <td>0.2</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>5.1</td>\n      <td>3.3</td>\n      <td>1.7</td>\n      <td>0.5</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>4.8</td>\n      <td>3.4</td>\n      <td>1.9</td>\n      <td>0.2</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>5.0</td>\n      <td>3.0</td>\n      <td>1.6</td>\n      <td>0.2</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>5.0</td>\n      <td>3.4</td>\n      <td>1.6</td>\n      <td>0.4</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>5.2</td>\n      <td>3.5</td>\n      <td>1.5</td>\n      <td>0.2</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>5.2</td>\n      <td>3.4</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>4.7</td>\n      <td>3.2</td>\n      <td>1.6</td>\n      <td>0.2</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>120</th>\n      <td>6.9</td>\n      <td>3.2</td>\n      <td>5.7</td>\n      <td>2.3</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>121</th>\n      <td>5.6</td>\n      <td>2.8</td>\n      <td>4.9</td>\n      <td>2.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>122</th>\n      <td>7.7</td>\n      <td>2.8</td>\n      <td>6.7</td>\n      <td>2.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>123</th>\n      <td>6.3</td>\n      <td>2.7</td>\n      <td>4.9</td>\n      <td>1.8</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>124</th>\n      <td>6.7</td>\n      <td>3.3</td>\n      <td>5.7</td>\n      <td>2.1</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>125</th>\n      <td>7.2</td>\n      <td>3.2</td>\n      <td>6.0</td>\n      <td>1.8</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>126</th>\n      <td>6.2</td>\n      <td>2.8</td>\n      <td>4.8</td>\n      <td>1.8</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>127</th>\n      <td>6.1</td>\n      <td>3.0</td>\n      <td>4.9</td>\n      <td>1.8</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>128</th>\n      <td>6.4</td>\n      <td>2.8</td>\n      <td>5.6</td>\n      <td>2.1</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>129</th>\n      <td>7.2</td>\n      <td>3.0</td>\n      <td>5.8</td>\n      <td>1.6</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>130</th>\n      <td>7.4</td>\n      <td>2.8</td>\n      <td>6.1</td>\n      <td>1.9</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>131</th>\n      <td>7.9</td>\n      <td>3.8</td>\n      <td>6.4</td>\n      <td>2.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>132</th>\n      <td>6.4</td>\n      <td>2.8</td>\n      <td>5.6</td>\n      <td>2.2</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>133</th>\n      <td>6.3</td>\n      <td>2.8</td>\n      <td>5.1</td>\n      <td>1.5</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>134</th>\n      <td>6.1</td>\n      <td>2.6</td>\n      <td>5.6</td>\n      <td>1.4</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>135</th>\n      <td>7.7</td>\n      <td>3.0</td>\n      <td>6.1</td>\n      <td>2.3</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>136</th>\n      <td>6.3</td>\n      <td>3.4</td>\n      <td>5.6</td>\n      <td>2.4</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>137</th>\n      <td>6.4</td>\n      <td>3.1</td>\n      <td>5.5</td>\n      <td>1.8</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>138</th>\n      <td>6.0</td>\n      <td>3.0</td>\n      <td>4.8</td>\n      <td>1.8</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>139</th>\n      <td>6.9</td>\n      <td>3.1</td>\n      <td>5.4</td>\n      <td>2.1</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>140</th>\n      <td>6.7</td>\n      <td>3.1</td>\n      <td>5.6</td>\n      <td>2.4</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>141</th>\n      <td>6.9</td>\n      <td>3.1</td>\n      <td>5.1</td>\n      <td>2.3</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>142</th>\n      <td>5.8</td>\n      <td>2.7</td>\n      <td>5.1</td>\n      <td>1.9</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>143</th>\n      <td>6.8</td>\n      <td>3.2</td>\n      <td>5.9</td>\n      <td>2.3</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>144</th>\n      <td>6.7</td>\n      <td>3.3</td>\n      <td>5.7</td>\n      <td>2.5</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>145</th>\n      <td>6.7</td>\n      <td>3.0</td>\n      <td>5.2</td>\n      <td>2.3</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>146</th>\n      <td>6.3</td>\n      <td>2.5</td>\n      <td>5.0</td>\n      <td>1.9</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>147</th>\n      <td>6.5</td>\n      <td>3.0</td>\n      <td>5.2</td>\n      <td>2.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>148</th>\n      <td>6.2</td>\n      <td>3.4</td>\n      <td>5.4</td>\n      <td>2.3</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>149</th>\n      <td>5.9</td>\n      <td>3.0</td>\n      <td>5.1</td>\n      <td>1.8</td>\n      <td>2.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>150 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abfffa52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n0                5.1               3.5                1.4               0.2   \n1                4.9               3.0                1.4               0.2   \n2                4.7               3.2                1.3               0.2   \n3                4.6               3.1                1.5               0.2   \n4                5.0               3.6                1.4               0.2   \n\n   target  \n0     0.0  \n1     0.0  \n2     0.0  \n3     0.0  \n4     0.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sepal length (cm)</th>\n      <th>sepal width (cm)</th>\n      <th>petal length (cm)</th>\n      <th>petal width (cm)</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5.1</td>\n      <td>3.5</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4.9</td>\n      <td>3.0</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4.7</td>\n      <td>3.2</td>\n      <td>1.3</td>\n      <td>0.2</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4.6</td>\n      <td>3.1</td>\n      <td>1.5</td>\n      <td>0.2</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5.0</td>\n      <td>3.6</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18ca042f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n145                6.7               3.0                5.2               2.3   \n146                6.3               2.5                5.0               1.9   \n147                6.5               3.0                5.2               2.0   \n148                6.2               3.4                5.4               2.3   \n149                5.9               3.0                5.1               1.8   \n\n     target  \n145     2.0  \n146     2.0  \n147     2.0  \n148     2.0  \n149     2.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sepal length (cm)</th>\n      <th>sepal width (cm)</th>\n      <th>petal length (cm)</th>\n      <th>petal width (cm)</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>145</th>\n      <td>6.7</td>\n      <td>3.0</td>\n      <td>5.2</td>\n      <td>2.3</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>146</th>\n      <td>6.3</td>\n      <td>2.5</td>\n      <td>5.0</td>\n      <td>1.9</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>147</th>\n      <td>6.5</td>\n      <td>3.0</td>\n      <td>5.2</td>\n      <td>2.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>148</th>\n      <td>6.2</td>\n      <td>3.4</td>\n      <td>5.4</td>\n      <td>2.3</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>149</th>\n      <td>5.9</td>\n      <td>3.0</td>\n      <td>5.1</td>\n      <td>1.8</td>\n      <td>2.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10fe19bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('target',axis=1) # X is the i/p features and this target is dropped \n",
    "y = df['target'] # y is the o/p for x features ===NOTE===> THEY ARE PANDAS DATAFRAME."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "628de8e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "pandas.core.frame.DataFrame"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d010907",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "pandas.core.series.Series"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d004255f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.values # ===NOTE===> X and y converted into numpy arrays\n",
    "y = y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3dd3932c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "numpy.ndarray"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8aa3ccfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 2., 2.,\n       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.])"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0502cd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This divide the whole dataset into training and test i/p data and o/p data automatically.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=33) \n",
    "# Random state is the seed for random values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e8d6215",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[5.6, 2.7, 4.2, 1.3],\n       [6.7, 3.1, 4.7, 1.5],\n       [5.6, 2.8, 4.9, 2. ],\n       [6.4, 3.2, 5.3, 2.3],\n       [6.7, 3.1, 5.6, 2.4],\n       [6.7, 3. , 5.2, 2.3],\n       [5.8, 2.7, 5.1, 1.9],\n       [5.7, 3. , 4.2, 1.2],\n       [5. , 2.3, 3.3, 1. ],\n       [4.9, 3.1, 1.5, 0.1],\n       [6.3, 2.3, 4.4, 1.3],\n       [5.8, 2.6, 4. , 1.2],\n       [6.2, 2.9, 4.3, 1.3],\n       [4.7, 3.2, 1.3, 0.2],\n       [4.6, 3.4, 1.4, 0.3],\n       [5.1, 2.5, 3. , 1.1],\n       [4.8, 3.4, 1.6, 0.2],\n       [7.9, 3.8, 6.4, 2. ],\n       [5.1, 3.4, 1.5, 0.2],\n       [5.1, 3.7, 1.5, 0.4],\n       [5.6, 2.9, 3.6, 1.3],\n       [6.5, 3. , 5.5, 1.8],\n       [5.4, 3.9, 1.7, 0.4],\n       [7. , 3.2, 4.7, 1.4],\n       [5.8, 2.8, 5.1, 2.4],\n       [7.7, 2.6, 6.9, 2.3],\n       [5.5, 2.5, 4. , 1.3],\n       [5.9, 3.2, 4.8, 1.8],\n       [4.9, 3.1, 1.5, 0.1],\n       [4.5, 2.3, 1.3, 0.3],\n       [6.3, 2.8, 5.1, 1.5],\n       [4.4, 2.9, 1.4, 0.2],\n       [5. , 3.6, 1.4, 0.2],\n       [7.2, 3. , 5.8, 1.6],\n       [6. , 3.4, 4.5, 1.6],\n       [6.2, 2.2, 4.5, 1.5],\n       [7.4, 2.8, 6.1, 1.9],\n       [6.8, 3. , 5.5, 2.1],\n       [6.4, 2.8, 5.6, 2.2],\n       [5.7, 2.5, 5. , 2. ],\n       [5. , 3.5, 1.6, 0.6],\n       [5.1, 3.8, 1.5, 0.3],\n       [6.8, 2.8, 4.8, 1.4],\n       [5.2, 2.7, 3.9, 1.4],\n       [5.1, 3.8, 1.6, 0.2],\n       [5.6, 2.5, 3.9, 1.1],\n       [6.1, 3. , 4.9, 1.8],\n       [6.6, 2.9, 4.6, 1.3],\n       [6.4, 2.8, 5.6, 2.1],\n       [4.3, 3. , 1.1, 0.1],\n       [7.2, 3.6, 6.1, 2.5],\n       [5.1, 3.5, 1.4, 0.2],\n       [6.3, 2.5, 4.9, 1.5],\n       [4.4, 3.2, 1.3, 0.2],\n       [7.6, 3. , 6.6, 2.1],\n       [6.4, 3.2, 4.5, 1.5],\n       [5.1, 3.8, 1.9, 0.4],\n       [6.5, 3.2, 5.1, 2. ],\n       [6.3, 2.7, 4.9, 1.8],\n       [5. , 3.5, 1.3, 0.3],\n       [5.2, 3.4, 1.4, 0.2],\n       [6.4, 2.7, 5.3, 1.9],\n       [5.8, 4. , 1.2, 0.2],\n       [5.7, 4.4, 1.5, 0.4],\n       [4.6, 3.2, 1.4, 0.2],\n       [6.9, 3.1, 5.4, 2.1],\n       [6.3, 2.9, 5.6, 1.8],\n       [5.5, 3.5, 1.3, 0.2],\n       [5.7, 2.6, 3.5, 1. ],\n       [5. , 3.3, 1.4, 0.2],\n       [6. , 2.2, 4. , 1. ],\n       [4.9, 3. , 1.4, 0.2],\n       [5. , 2. , 3.5, 1. ],\n       [6.6, 3. , 4.4, 1.4],\n       [5.7, 2.8, 4.5, 1.3],\n       [5.5, 2.6, 4.4, 1.2],\n       [5.5, 2.3, 4. , 1.3],\n       [4.8, 3.1, 1.6, 0.2],\n       [6. , 2.9, 4.5, 1.5],\n       [5. , 3. , 1.6, 0.2],\n       [6.9, 3.1, 4.9, 1.5],\n       [6.7, 2.5, 5.8, 1.8],\n       [5.3, 3.7, 1.5, 0.2],\n       [5.2, 4.1, 1.5, 0.1],\n       [5. , 3.4, 1.6, 0.4],\n       [4.6, 3.6, 1. , 0.2],\n       [7.7, 3.8, 6.7, 2.2],\n       [7.3, 2.9, 6.3, 1.8],\n       [4.6, 3.1, 1.5, 0.2],\n       [5.5, 2.4, 3.7, 1. ],\n       [5.8, 2.7, 3.9, 1.2],\n       [6.7, 3.3, 5.7, 2.1],\n       [5.8, 2.7, 4.1, 1. ],\n       [5.4, 3.7, 1.5, 0.2],\n       [5. , 3.4, 1.5, 0.2],\n       [6. , 2.7, 5.1, 1.6],\n       [5.7, 2.8, 4.1, 1.3],\n       [6.1, 2.8, 4.7, 1.2],\n       [5.1, 3.3, 1.7, 0.5],\n       [5.6, 3. , 4.1, 1.3],\n       [5.4, 3. , 4.5, 1.5],\n       [5.4, 3.9, 1.3, 0.4],\n       [6.7, 3.3, 5.7, 2.5],\n       [4.9, 2.5, 4.5, 1.7],\n       [6.2, 3.4, 5.4, 2.3],\n       [5.5, 2.4, 3.8, 1.1],\n       [7.7, 2.8, 6.7, 2. ],\n       [5.4, 3.4, 1.5, 0.4],\n       [6.7, 3. , 5. , 1.7],\n       [5.5, 4.2, 1.4, 0.2],\n       [5. , 3.2, 1.2, 0.2],\n       [4.8, 3. , 1.4, 0.3],\n       [5.8, 2.7, 5.1, 1.9],\n       [5.9, 3. , 4.2, 1.5],\n       [7.1, 3. , 5.9, 2.1],\n       [4.9, 2.4, 3.3, 1. ],\n       [6.3, 2.5, 5. , 1.9],\n       [5.6, 3. , 4.5, 1.5],\n       [7.7, 3. , 6.1, 2.3],\n       [5.4, 3.4, 1.7, 0.2]])"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "648badef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "numpy.ndarray"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a4d7d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.FloatTensor(X_train)\n",
    "X_test = torch.FloatTensor(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c3127dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Tensor"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c5adb1ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[5.6000, 2.7000, 4.2000, 1.3000],\n        [6.7000, 3.1000, 4.7000, 1.5000],\n        [5.6000, 2.8000, 4.9000, 2.0000],\n        [6.4000, 3.2000, 5.3000, 2.3000],\n        [6.7000, 3.1000, 5.6000, 2.4000],\n        [6.7000, 3.0000, 5.2000, 2.3000],\n        [5.8000, 2.7000, 5.1000, 1.9000],\n        [5.7000, 3.0000, 4.2000, 1.2000],\n        [5.0000, 2.3000, 3.3000, 1.0000],\n        [4.9000, 3.1000, 1.5000, 0.1000],\n        [6.3000, 2.3000, 4.4000, 1.3000],\n        [5.8000, 2.6000, 4.0000, 1.2000],\n        [6.2000, 2.9000, 4.3000, 1.3000],\n        [4.7000, 3.2000, 1.3000, 0.2000],\n        [4.6000, 3.4000, 1.4000, 0.3000],\n        [5.1000, 2.5000, 3.0000, 1.1000],\n        [4.8000, 3.4000, 1.6000, 0.2000],\n        [7.9000, 3.8000, 6.4000, 2.0000],\n        [5.1000, 3.4000, 1.5000, 0.2000],\n        [5.1000, 3.7000, 1.5000, 0.4000],\n        [5.6000, 2.9000, 3.6000, 1.3000],\n        [6.5000, 3.0000, 5.5000, 1.8000],\n        [5.4000, 3.9000, 1.7000, 0.4000],\n        [7.0000, 3.2000, 4.7000, 1.4000],\n        [5.8000, 2.8000, 5.1000, 2.4000],\n        [7.7000, 2.6000, 6.9000, 2.3000],\n        [5.5000, 2.5000, 4.0000, 1.3000],\n        [5.9000, 3.2000, 4.8000, 1.8000],\n        [4.9000, 3.1000, 1.5000, 0.1000],\n        [4.5000, 2.3000, 1.3000, 0.3000],\n        [6.3000, 2.8000, 5.1000, 1.5000],\n        [4.4000, 2.9000, 1.4000, 0.2000],\n        [5.0000, 3.6000, 1.4000, 0.2000],\n        [7.2000, 3.0000, 5.8000, 1.6000],\n        [6.0000, 3.4000, 4.5000, 1.6000],\n        [6.2000, 2.2000, 4.5000, 1.5000],\n        [7.4000, 2.8000, 6.1000, 1.9000],\n        [6.8000, 3.0000, 5.5000, 2.1000],\n        [6.4000, 2.8000, 5.6000, 2.2000],\n        [5.7000, 2.5000, 5.0000, 2.0000],\n        [5.0000, 3.5000, 1.6000, 0.6000],\n        [5.1000, 3.8000, 1.5000, 0.3000],\n        [6.8000, 2.8000, 4.8000, 1.4000],\n        [5.2000, 2.7000, 3.9000, 1.4000],\n        [5.1000, 3.8000, 1.6000, 0.2000],\n        [5.6000, 2.5000, 3.9000, 1.1000],\n        [6.1000, 3.0000, 4.9000, 1.8000],\n        [6.6000, 2.9000, 4.6000, 1.3000],\n        [6.4000, 2.8000, 5.6000, 2.1000],\n        [4.3000, 3.0000, 1.1000, 0.1000],\n        [7.2000, 3.6000, 6.1000, 2.5000],\n        [5.1000, 3.5000, 1.4000, 0.2000],\n        [6.3000, 2.5000, 4.9000, 1.5000],\n        [4.4000, 3.2000, 1.3000, 0.2000],\n        [7.6000, 3.0000, 6.6000, 2.1000],\n        [6.4000, 3.2000, 4.5000, 1.5000],\n        [5.1000, 3.8000, 1.9000, 0.4000],\n        [6.5000, 3.2000, 5.1000, 2.0000],\n        [6.3000, 2.7000, 4.9000, 1.8000],\n        [5.0000, 3.5000, 1.3000, 0.3000],\n        [5.2000, 3.4000, 1.4000, 0.2000],\n        [6.4000, 2.7000, 5.3000, 1.9000],\n        [5.8000, 4.0000, 1.2000, 0.2000],\n        [5.7000, 4.4000, 1.5000, 0.4000],\n        [4.6000, 3.2000, 1.4000, 0.2000],\n        [6.9000, 3.1000, 5.4000, 2.1000],\n        [6.3000, 2.9000, 5.6000, 1.8000],\n        [5.5000, 3.5000, 1.3000, 0.2000],\n        [5.7000, 2.6000, 3.5000, 1.0000],\n        [5.0000, 3.3000, 1.4000, 0.2000],\n        [6.0000, 2.2000, 4.0000, 1.0000],\n        [4.9000, 3.0000, 1.4000, 0.2000],\n        [5.0000, 2.0000, 3.5000, 1.0000],\n        [6.6000, 3.0000, 4.4000, 1.4000],\n        [5.7000, 2.8000, 4.5000, 1.3000],\n        [5.5000, 2.6000, 4.4000, 1.2000],\n        [5.5000, 2.3000, 4.0000, 1.3000],\n        [4.8000, 3.1000, 1.6000, 0.2000],\n        [6.0000, 2.9000, 4.5000, 1.5000],\n        [5.0000, 3.0000, 1.6000, 0.2000],\n        [6.9000, 3.1000, 4.9000, 1.5000],\n        [6.7000, 2.5000, 5.8000, 1.8000],\n        [5.3000, 3.7000, 1.5000, 0.2000],\n        [5.2000, 4.1000, 1.5000, 0.1000],\n        [5.0000, 3.4000, 1.6000, 0.4000],\n        [4.6000, 3.6000, 1.0000, 0.2000],\n        [7.7000, 3.8000, 6.7000, 2.2000],\n        [7.3000, 2.9000, 6.3000, 1.8000],\n        [4.6000, 3.1000, 1.5000, 0.2000],\n        [5.5000, 2.4000, 3.7000, 1.0000],\n        [5.8000, 2.7000, 3.9000, 1.2000],\n        [6.7000, 3.3000, 5.7000, 2.1000],\n        [5.8000, 2.7000, 4.1000, 1.0000],\n        [5.4000, 3.7000, 1.5000, 0.2000],\n        [5.0000, 3.4000, 1.5000, 0.2000],\n        [6.0000, 2.7000, 5.1000, 1.6000],\n        [5.7000, 2.8000, 4.1000, 1.3000],\n        [6.1000, 2.8000, 4.7000, 1.2000],\n        [5.1000, 3.3000, 1.7000, 0.5000],\n        [5.6000, 3.0000, 4.1000, 1.3000],\n        [5.4000, 3.0000, 4.5000, 1.5000],\n        [5.4000, 3.9000, 1.3000, 0.4000],\n        [6.7000, 3.3000, 5.7000, 2.5000],\n        [4.9000, 2.5000, 4.5000, 1.7000],\n        [6.2000, 3.4000, 5.4000, 2.3000],\n        [5.5000, 2.4000, 3.8000, 1.1000],\n        [7.7000, 2.8000, 6.7000, 2.0000],\n        [5.4000, 3.4000, 1.5000, 0.4000],\n        [6.7000, 3.0000, 5.0000, 1.7000],\n        [5.5000, 4.2000, 1.4000, 0.2000],\n        [5.0000, 3.2000, 1.2000, 0.2000],\n        [4.8000, 3.0000, 1.4000, 0.3000],\n        [5.8000, 2.7000, 5.1000, 1.9000],\n        [5.9000, 3.0000, 4.2000, 1.5000],\n        [7.1000, 3.0000, 5.9000, 2.1000],\n        [4.9000, 2.4000, 3.3000, 1.0000],\n        [6.3000, 2.5000, 5.0000, 1.9000],\n        [5.6000, 3.0000, 4.5000, 1.5000],\n        [7.7000, 3.0000, 6.1000, 2.3000],\n        [5.4000, 3.4000, 1.7000, 0.2000]])"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8bfb7205",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = torch.LongTensor(y_train)\n",
    "y_test = torch.LongTensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "933e1a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(4)\n",
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cff3fbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "480b3d2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<bound method Module.parameters of Model(\n  (fc1): Linear(in_features=4, out_features=8, bias=True)\n  (fc2): Linear(in_features=8, out_features=9, bias=True)\n  (out): Linear(in_features=9, out_features=3, bias=True)\n)>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c195a02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 & Loss: 1.0956822633743286\n",
      "Epoch: 11 & Loss: 0.9819066524505615\n",
      "Epoch: 21 & Loss: 0.79116290807724\n",
      "Epoch: 31 & Loss: 0.5399959683418274\n",
      "Epoch: 41 & Loss: 0.35664159059524536\n",
      "Epoch: 51 & Loss: 0.22170095145702362\n",
      "Epoch: 61 & Loss: 0.1289195567369461\n",
      "Epoch: 71 & Loss: 0.08875247836112976\n",
      "Epoch: 81 & Loss: 0.07240226864814758\n",
      "Epoch: 91 & Loss: 0.0646730437874794\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "losses = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    i += 1\n",
    "    y_pred = model.forward(X_train)\n",
    "    \n",
    "    loss = criterion(y_pred, y_train)\n",
    "    \n",
    "    losses.append(loss)\n",
    "    \n",
    "    if i%10 == 1:\n",
    "        print(f'Epoch: {i} & Loss: {loss}')\n",
    "        \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c136aaf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Text(0.5, 0, 'Epoch')"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(epochs),[loss.item() for loss in losses])\n",
    "plt.ylabel('LOSS')\n",
    "plt.xlabel('Epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "99f3d385",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    y_eval = model.forward(X_test)\n",
    "    loss = criterion(y_eval, y_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ae596e07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(0.0609)"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b06c80c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1=>  tensor([ 3.9362, 11.8163,  6.0314])  ans:1\n",
      "2=>  tensor([ 5.1330, 13.2102,  5.5338])  ans:1\n",
      "3=>  tensor([15.8133,  9.9178,  0.0000])  ans:0\n",
      "4=>  tensor([ 2.7497, 12.7803,  9.0323])  ans:1\n",
      "5=>  tensor([ 0.0000, 12.4402, 15.7179])  ans:2\n",
      "6=>  tensor([ 0.0000, 12.8932, 22.6558])  ans:2\n",
      "7=>  tensor([16.2079, 10.2480,  0.0000])  ans:0\n",
      "8=>  tensor([16.8392, 10.4613,  0.0000])  ans:0\n",
      "9=>  tensor([ 0.0000, 12.9876, 15.3816])  ans:2\n",
      "10=>  tensor([ 0.0000, 13.5613, 18.9499])  ans:2\n",
      "11=>  tensor([ 0.0000, 13.4885, 20.2893])  ans:2\n",
      "12=>  tensor([15.0628,  9.3503,  0.0000])  ans:0\n",
      "13=>  tensor([ 0.0000, 12.8901, 19.1390])  ans:2\n",
      "14=>  tensor([ 2.4699, 12.4087,  9.0952])  ans:1\n",
      "15=>  tensor([ 0.0000, 13.3406, 15.8232])  ans:2\n",
      "16=>  tensor([ 4.8068, 12.7118,  5.5457])  ans:1\n",
      "17=>  tensor([ 0.4437, 12.2442, 12.2785])  ans:2\n",
      "18=>  tensor([17.1069, 10.6343,  0.0000])  ans:0\n",
      "19=>  tensor([ 3.1121, 12.8572,  8.5020])  ans:1\n",
      "20=>  tensor([ 0.0000, 14.1767, 16.6831])  ans:2\n",
      "21=>  tensor([16.1579, 10.0863,  0.0000])  ans:0\n",
      "22=>  tensor([18.2534, 11.4378,  0.0000])  ans:0\n",
      "23=>  tensor([ 0.0000, 12.9900, 20.3013])  ans:2\n",
      "24=>  tensor([15.8645,  9.8795,  0.0000])  ans:0\n",
      "25=>  tensor([ 0.0000, 11.8624, 14.7505])  ans:2\n",
      "26=>  tensor([ 0.1887, 12.3596, 12.8294])  ans:2\n",
      "27=>  tensor([ 3.1116, 12.4495,  8.0730])  ans:1\n",
      "28=>  tensor([ 5.0103, 12.1953,  4.6593])  ans:1\n",
      "29=>  tensor([ 0.0000, 12.9020, 15.3121])  ans:2\n",
      "30=>  tensor([ 0.0000, 12.1970, 14.2106])  ans:2\n",
      "we got 30 correct!\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(X_test):\n",
    "        y_val = model.forward(data)\n",
    "        print(f'{i+1}=>  {str(y_val)}  ans:{y_test[i]}')\n",
    "        if y_val.argmax().item() == y_test[i]:\n",
    "            correct += 1\n",
    "print(f'we got {correct} correct!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6e2cd740",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),r'C:\\AnCodeRR\\iris_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "81e6c6a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model = Model()\n",
    "new_model.load_state_dict(torch.load(r'C:\\AnCodeRR\\iris_model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "09ede38a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Model(\n  (fc1): Linear(in_features=4, out_features=8, bias=True)\n  (fc2): Linear(in_features=8, out_features=9, bias=True)\n  (out): Linear(in_features=9, out_features=3, bias=True)\n)"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d54b0640",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_data = torch.tensor([5.6,3.7,2.2,0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d1246f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    ans = new_model(ind_data)\n",
    "    print(ans.argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f7f278bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}